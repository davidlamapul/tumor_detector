{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras.metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utilities\n",
    "from utilities import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "os.chdir('data/Healthcare AI Datasets/Brain_MRI')\n",
    "brain_df = pd.read_csv('data_mask.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
    "brain_df_mask.shape\n",
    "\n",
    "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
    "\n",
    "train_ids = list(X_train.image_path)\n",
    "train_mask = list(X_train.mask_path)\n",
    "\n",
    "val_ids = list(X_val.image_path)\n",
    "val_mask= list(X_val.mask_path)\n",
    "\n",
    "training_generator = DataGenerator(train_ids,train_mask)\n",
    "validation_generator = DataGenerator(val_ids,val_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RESUNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 64  256         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 256, 256, 64  0          ['conv2d_1[0][0]',               \n",
      " da)                            )                                 'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  73856       ['activation_1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  8320        ['tf.__operators__.add[0][0]']   \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_4[0][0]',               \n",
      " mbda)                          8)                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 256)  295168      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 256)  33024       ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_7[0][0]',               \n",
      " mbda)                                                            'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 512)  1180160     ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  131584      ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 32, 32, 512)  0          ['conv2d_10[0][0]',              \n",
      " mbda)                                                            'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 64, 512)  0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 768)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 768)  3072       ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 768)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  196864      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_13[0][0]',              \n",
      " mbda)                                                            'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 25  0          ['tf.__operators__.add_4[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_1[0][0]',        \n",
      "                                4)                                'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128, 128, 38  1536       ['concatenate_1[0][0]']          \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 128, 128, 38  0           ['batch_normalization_9[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  442496      ['activation_9[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_10[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  147584      ['activation_10[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  49280       ['concatenate_1[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_16[0][0]',              \n",
      " mbda)                          8)                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 12  0          ['tf.__operators__.add_5[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_2[0][0]',        \n",
      "                                2)                                'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 256, 256, 19  768        ['concatenate_2[0][0]']          \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 256, 256, 19  0           ['batch_normalization_11[0][0]'] \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 64  110656      ['activation_11[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 64  256        ['conv2d_18[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 64  36928       ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  12352       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 256, 256, 64  0          ['conv2d_19[0][0]',              \n",
      " mbda)                          )                                 'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 1)  65          ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,227,393\n",
      "Trainable params: 8,220,993\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def batchnorm_relu(inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def residual_block(inputs, num_filters, strides=1):\n",
    "    # Convolutional Layers\n",
    "    x = batchnorm_relu(inputs)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", strides=strides)(x)\n",
    "    x = batchnorm_relu(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", strides=1)(x)\n",
    "\n",
    "    # Shortcut Connection (Identity Mapping)\n",
    "    s = Conv2D(num_filters, 1, padding=\"same\", strides=strides)(inputs)\n",
    "\n",
    "    x = x + s\n",
    "    return x\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = UpSampling2D((2, 2))(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = residual_block(x, num_filters, strides=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_resunet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Endoder 1\n",
    "    x = Conv2D(64, 3, padding=\"same\", strides=1)(inputs)\n",
    "    x = batchnorm_relu(x)\n",
    "    x = Conv2D(64, 3, padding=\"same\", strides=1)(x)\n",
    "    s = Conv2D(64, 1, padding=\"same\")(inputs) # Skip connection\n",
    "    s1 = x + s\n",
    "\n",
    "    # Encoder 1 & 2\n",
    "    s2 = residual_block(s1, 128, strides=2)\n",
    "    s3 = residual_block(s2, 256, strides=2)\n",
    "\n",
    "    # Bridge\n",
    "    b = residual_block(s3, 512, strides=2)\n",
    "\n",
    "    # Decoders\n",
    "    x = decoder_block(b, s3, 256)\n",
    "    x = decoder_block(x, s2, 128)\n",
    "    x = decoder_block(x, s1, 64)\n",
    "\n",
    "    # Classifier\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "    #Model\n",
    "    model = Model(inputs, outputs, name=\"RESUNET\")\n",
    "\n",
    "    return model\n",
    "\n",
    "shape = (256, 256, 3)\n",
    "model = build_resunet(shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss=utilities.tversky_loss,\n",
    "            metrics=['precision'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\utilities.py\", line 215, in tversky_loss  *\n        return 1 - tversky(y_true,y_pred)\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\utilities.py\", line 208, in tversky  *\n        true_pos = K.sum(y_true_pos * y_pred_pos)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_generator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\tumor_detector\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemafl1g2c.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezpk4cqci.py:12\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tversky_loss\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     11\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tversky), (ag__\u001B[38;5;241m.\u001B[39mld(y_true), ag__\u001B[38;5;241m.\u001B[39mld(y_pred)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqmjxlkx0.py:12\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tversky\u001B[1;34m(y_true, y_pred, smooth)\u001B[0m\n\u001B[0;32m     10\u001B[0m y_true_pos \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(K)\u001B[38;5;241m.\u001B[39mflatten, (ag__\u001B[38;5;241m.\u001B[39mld(y_true),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     11\u001B[0m y_pred_pos \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(K)\u001B[38;5;241m.\u001B[39mflatten, (ag__\u001B[38;5;241m.\u001B[39mld(y_pred),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m---> 12\u001B[0m true_pos \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(K)\u001B[38;5;241m.\u001B[39msum, (\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true_pos\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred_pos\u001B[49m\u001B[43m)\u001B[49m,), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     13\u001B[0m false_neg \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(K)\u001B[38;5;241m.\u001B[39msum, (ag__\u001B[38;5;241m.\u001B[39mld(y_true_pos) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_pred_pos)),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     14\u001B[0m false_pos \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(K)\u001B[38;5;241m.\u001B[39msum, ((\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_true_pos)) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_pred_pos),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n",
      "\u001B[1;31mTypeError\u001B[0m: in user code:\n\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\utilities.py\", line 215, in tversky_loss  *\n        return 1 - tversky(y_true,y_pred)\n    File \"C:\\Users\\dapal\\PycharmProjects\\tumor_detector\\utilities.py\", line 208, in tversky  *\n        true_pos = K.sum(y_true_pos * y_pred_pos)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int32 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_generator,\n",
    "                    epochs = 10,\n",
    "                    validation_data=validation_generator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[[[-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          ...,\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942]],\n \n         [[-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          ...,\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942]],\n \n         [[-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          ...,\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942],\n          [-0.73115752, -0.73115752, -0.70381942]],\n \n         ...,\n \n         [[-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          ...,\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752]],\n \n         [[-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          ...,\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752]],\n \n         [[-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          ...,\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752],\n          [-0.73115752, -0.73115752, -0.73115752]]],\n \n \n        [[[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]],\n \n         [[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]],\n \n         [[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]],\n \n         ...,\n \n         [[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]],\n \n         [[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]],\n \n         [[-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          ...,\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993],\n          [-0.68183993, -0.68183993, -0.68183993]]],\n \n \n        [[[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]],\n \n         [[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]],\n \n         [[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]],\n \n         ...,\n \n         [[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]],\n \n         [[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]],\n \n         [[-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          ...,\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403],\n          [-0.74221403, -0.74221403, -0.74221403]]],\n \n \n        ...,\n \n \n        [[[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]],\n \n         [[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]],\n \n         [[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]],\n \n         ...,\n \n         [[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]],\n \n         [[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]],\n \n         [[-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          ...,\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336],\n          [-0.70306336, -0.70306336, -0.70306336]]],\n \n \n        [[[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.81185397, -0.81185397],\n          ...,\n          [-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.81185397, -0.81185397]],\n \n         [[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.69091652, -0.81185397],\n          [-0.81185397, -0.6304478 , -0.81185397],\n          ...,\n          [-0.81185397, -0.75138524, -0.81185397],\n          [-0.7816196 , -0.7816196 , -0.81185397],\n          [-0.7816196 , -0.69091652, -0.81185397]],\n \n         [[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.72115088, -0.81185397],\n          [-0.81185397, -0.66068216, -0.81185397],\n          ...,\n          [-0.75138524, -0.81185397, -0.81185397],\n          [-0.75138524, -0.7816196 , -0.81185397],\n          [-0.72115088, -0.72115088, -0.81185397]],\n \n         ...,\n \n         [[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.69091652, -0.81185397],\n          [-0.81185397, -0.66068216, -0.81185397],\n          ...,\n          [-0.72115088, -0.7816196 , -0.81185397],\n          [-0.72115088, -0.72115088, -0.81185397],\n          [-0.81185397, -0.72115088, -0.81185397]],\n \n         [[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.75138524, -0.81185397],\n          [-0.81185397, -0.69091652, -0.81185397],\n          ...,\n          [-0.75138524, -0.72115088, -0.81185397],\n          [-0.72115088, -0.72115088, -0.81185397],\n          [-0.81185397, -0.75138524, -0.81185397]],\n \n         [[-0.81185397, -0.81185397, -0.81185397],\n          [-0.81185397, -0.7816196 , -0.81185397],\n          [-0.81185397, -0.7816196 , -0.81185397],\n          ...,\n          [-0.7816196 , -0.81185397, -0.81185397],\n          [-0.7816196 , -0.6304478 , -0.81185397],\n          [-0.81185397, -0.66068216, -0.81185397]]],\n \n \n        [[[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]],\n \n         [[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]],\n \n         [[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]],\n \n         ...,\n \n         [[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]],\n \n         [[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]],\n \n         [[-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          ...,\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359],\n          [-0.77321359, -0.77321359, -0.77321359]]]]),\n array([[[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]],\n \n \n        [[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]],\n \n \n        [[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]],\n \n \n        ...,\n \n \n        [[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]],\n \n \n        [[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]],\n \n \n        [[[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         ...,\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]],\n \n         [[0],\n          [0],\n          [0],\n          ...,\n          [0],\n          [0],\n          [0]]]]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}